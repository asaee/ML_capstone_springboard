{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cf3785",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45473135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import time\n",
    "\n",
    "# Model selection\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# performance metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f482da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/covid_articles_tfidf.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caace9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.topic_area.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1decacf",
   "metadata": {},
   "source": [
    "Since the number of articles per topic area are not balanced, I will filter out the tags with low frequency. Alternatively, I may merge the excluded tags with the closest tag with higher frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68eb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 10000\n",
    "\n",
    "filter_topics = df['topic_area'].value_counts().to_frame()\n",
    "filter_topics = filter_topics[filter_topics['topic_area']>min_samples].index\n",
    "df_majority = df[df['topic_area'].isin(filter_topics)].drop(columns='title')\n",
    "print(df_majority.shape)\n",
    "df_majority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78637e",
   "metadata": {},
   "source": [
    "### Encode labels\n",
    "We can use onehotencoder or label encoder to transform the labels. However, scikit learn can digest text labels and I will use text labels for now. The script below will be used if I need encoded labels in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_enc(array):\n",
    "    enc = LabelEncoder()\n",
    "    #y = df_majority.topic_area.values\n",
    "    array = enc.fit_transform(array)\n",
    "    n_classes = len(enc.classes_[0])\n",
    "    return array, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d89af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_enc(array):\n",
    "    enc = OrdinalEncoder()\n",
    "    #y = df_majority.topic_area.values\n",
    "    array = enc.fit_transform(array.reshape(-1,1))\n",
    "    n_classes = len(enc.categories_[0])\n",
    "    return array, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac74f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_enc(array):\n",
    "    enc = OneHotEncoder()\n",
    "    #y = df_majority.topic_area.values.reshape(-1,1)\n",
    "    array = enc.fit_transform(array.reshape(-1,1)).toarray()\n",
    "    n_classes = len(enc.categories_[0])\n",
    "    #print((enc.categories_))\n",
    "    return array, n_classes, enc.categories_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185be28",
   "metadata": {},
   "source": [
    "### ROC Curve for Multiclass Classification\n",
    "\n",
    "ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the “ideal” point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.\n",
    "\n",
    "I use the following function to generate ROC curve for the exisitng multi-class problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d73b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_calc(y_test, y_pred_prob):\n",
    "    \n",
    "    y_test_enc, n_classes, _ = onehot_enc(y_test)\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_enc[:, i], y_pred_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    return fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(fpr, tpr, roc_auc):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[0], tpr[0], color='r',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "    plt.plot([0, 1], [0, 1], color='b', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31cabd",
   "metadata": {},
   "source": [
    "### Precision Recall Curve\n",
    "\n",
    "Intuitively, precision is the ability of the classifier not to label as positive a sample that is negative, and recall is the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The precision_recall_curve computes a precision-recall curve from the ground truth label and a score given by the classifier by varying a decision threshold. I use the follwoing function to calculate and plot the precision and recall for the existing multi-class problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each class\n",
    "def pre_rec_calc(y_test, y_pred_prob):\n",
    "    \n",
    "    y_test_enc, n_classes, _ = onehot_enc(y_test)\n",
    "    \n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_test_enc[:, i], y_pred_prob[:, i])\n",
    "        average_precision[i] = average_precision_score(y_test_enc[:, i], y_pred_prob[:, i])\n",
    "    \n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(\n",
    "        y_test_enc.ravel(), y_pred_prob.ravel()\n",
    "    )\n",
    "    average_precision[\"micro\"] = average_precision_score(y_test_enc, y_pred_prob, average=\"micro\")\n",
    "    \n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[\"micro\"],\n",
    "        precision=precision[\"micro\"],\n",
    "        average_precision=average_precision[\"micro\"],\n",
    "    )\n",
    "    display.plot()\n",
    "    _ = display.ax_.set_title(\"Micro-averaged over all classes\")\n",
    "    \n",
    "    return precision, recall, average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup plot details\n",
    "def pre_rec_plot(precision, recall, average_precision):\n",
    "    \n",
    "    y_test_enc, n_classes, categories = onehot_enc(y_test)\n",
    "    \n",
    "    colors = cycle([\"navy\", \"turquoise\", \"darkorange\", \"cornflowerblue\", \"teal\"])\n",
    "    \n",
    "    _, ax = plt.subplots(figsize=(7, 8))\n",
    "    \n",
    "    f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "    lines, labels = [], []\n",
    "    for f_score in f_scores:\n",
    "        x = np.linspace(0.01, 1)\n",
    "        y = f_score * x / (2 * x - f_score)\n",
    "        (l,) = plt.plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n",
    "        plt.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "        \n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall[\"micro\"],\n",
    "        precision=precision[\"micro\"],\n",
    "        average_precision=average_precision[\"micro\"],\n",
    "    )\n",
    "    \n",
    "    display.plot(ax=ax, name=\"Micro-average precision-recall\", color=\"gold\")\n",
    "        \n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        display = PrecisionRecallDisplay(\n",
    "            recall=recall[i],\n",
    "            precision=precision[i],\n",
    "            average_precision=average_precision[i],\n",
    "        )\n",
    "        display.plot(ax=ax, name=f\"Precision-recall for class {categories[i]}\", color=color)\n",
    "    # add the legend for the iso-f1 curves\n",
    "    handles, labels = display.ax_.get_legend_handles_labels()\n",
    "    handles.extend([l])\n",
    "    labels.extend([\"iso-f1 curves\"])\n",
    "    # set the legend and the axes\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.legend(handles=handles, labels=labels, loc=\"best\")\n",
    "    ax.set_title(\"Extension of Precision-Recall curve to multi-class\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2f21e",
   "metadata": {},
   "source": [
    "### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_majority.drop(columns='topic_area')\n",
    "y = df_majority.topic_area.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b102d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_classes = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = dict(zip(np.unique(y_train), weights_classes))\n",
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [weight_dict[x] for x in y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662fe60",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "I will apply NaiveBayes, Logistic Regression, and SGD classifiers on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2693522a",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14093dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(X_train, y_train)#, sample_weight=weights)\n",
    "y_pred = clf_nb.predict(X_test)\n",
    "y_pred_prob = clf_nb.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452dbc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc = roc_calc(y_test, y_pred_prob)\n",
    "roc_plot(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efef670",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, average_precision = pre_rec_calc(y_test, y_pred_prob)\n",
    "pre_rec_plot(precision, recall, average_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ae67b",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15745826",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegressionCV()\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "y_pred_prob = clf_lr.predict_proba(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc = roc_calc(y_test, y_pred_prob)\n",
    "roc_plot(fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, average_precision = pre_rec_calc(y_test, y_pred_prob)\n",
    "pre_rec_plot(precision, recall, average_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b58659",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "y_pred = clf_sgd.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6825f76b",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "The next step I create a pipeline to put all these steps together and find an optimum hyperparamter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ded4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal_text = pd.read_csv('../data/interim/covid_articles_normalized.csv')\n",
    "\n",
    "min_samples = 10000\n",
    "\n",
    "filter_topics = df_normal_text['topic_area'].value_counts().to_frame()\n",
    "filter_topics = filter_topics[filter_topics['topic_area']>min_samples].index\n",
    "df_select_topics = df_normal_text[df_normal_text['topic_area'].isin(filter_topics)].drop(columns='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_select_topics.content.tolist()\n",
    "y = df_select_topics.topic_area.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fff26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'vect__max_features': [10000, 15000, 30000, None],\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': [1, 1e-1, 1e-2],\n",
    "    'clf__sample_weight':[None, weights],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(pipeline, param_grid, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(param_grid)\n",
    "t0 = time()\n",
    "\n",
    "search.fit(data.data, data.target)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
